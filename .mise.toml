# mise - Polyglot tool version manager + task runner
# https://mise.jdx.dev/configuration.html
# PercyBrain Testing Framework - Kent Beck Edition

# ============================================================================
# MINIMUM VERSION REQUIREMENT
# ============================================================================
min_version = "2025.10.0"

# ============================================================================
# TOOL VERSIONS
# ============================================================================
[tools]
lua = "5.1"
node = { version = "22.17.1", postinstall = "npm install -g neovim" }
python = "3.12"
stylua = "latest"

# ============================================================================
# ENVIRONMENT VARIABLES
# ============================================================================
[env]
# Lua module paths for require() in tests and development
LUA_PATH = "./lua/?.lua;./lua/?/init.lua;./tests/?.lua;./tests/?/init.lua;;"
LUA_CPATH = ""

# Test environment configuration
TEST_ENV = "isolated"
TEST_PARALLEL = "false"  # Neovim tests can't run in parallel
TEST_VERBOSITY = "normal"  # normal|verbose|minimal

# Suppress npm noise during installations
NPM_CONFIG_AUDIT = "false"
NPM_CONFIG_FUND = "false"
NODE_ENV = "development"

# ============================================================================
# SETTINGS
# ============================================================================
[settings]
not_found_auto_install = true
task_output = "prefix"
jobs = 4
trusted_config_paths = ["~/.config/nvim"]
experimental = true
idiomatic_version_file_enable_tools = ["node", "python"]

# ============================================================================
# TESTING FRAMEWORK - KENT BECK ARCHITECTURE
# ============================================================================

# ----------------------------------------------------------------------------
# TEST RUNNER HELPER (Internal - Do Not Call Directly)
# ----------------------------------------------------------------------------
[tasks."test:_run_plenary_dir"]
description = "Internal: Run plenary tests for a directory"
run = """
#!/bin/bash
TEST_DIR="$1"
if [ -z "$TEST_DIR" ]; then
  echo "Error: TEST_DIR required"
  exit 1
fi
nvim --headless -u tests/minimal_init.lua \
  -c "PlenaryBustedDirectory tests/$TEST_DIR/ {minimal_init = 'tests/minimal_init.lua'}" \
  -c "qa!"
"""

[tasks."test:_run_plenary_file"]
description = "Internal: Run plenary tests for a single file"
run = """
#!/bin/bash
TEST_FILE="$1"
if [ -z "$TEST_FILE" ]; then
  echo "Error: TEST_FILE required"
  exit 1
fi
nvim --headless -u tests/minimal_init.lua \
  -c "PlenaryBustedFile $TEST_FILE" \
  -c "qa!"
"""

# ----------------------------------------------------------------------------
# CONTRACT TESTS - Tests against specifications
# ----------------------------------------------------------------------------
[tasks."test:contract"]
description = "🔏 Contract Tests - Verify PercyBrain adheres to specifications"
alias = "tc"
run = "mise run test:_run_plenary_dir contract"
sources = ["tests/contract/**/*.lua", "specs/percybrain_contract.lua"]
outputs = [".cache/test/contract-results.json"]

[tasks."test:contract:watch"]
description = "🔏 Watch contract tests for changes"
run = """
mise run test:_watch test:contract "tests/contract/**/*.lua" "specs/percybrain_contract.lua"
"""

[tasks."test:contract:zettelkasten"]
description = "🔏 Test Zettelkasten contract specifications"
run = "mise run test:_run_plenary_file tests/contract/zettelkasten_templates_spec.lua"
sources = ["tests/contract/zettelkasten_templates_spec.lua", "lua/config/zettelkasten.lua"]

[tasks."test:contract:hugo"]
description = "🔏 Test Hugo frontmatter contract specifications"
run = "mise run test:_run_plenary_file tests/contract/hugo_frontmatter_spec.lua"
sources = ["tests/contract/hugo_frontmatter_spec.lua", "lua/percybrain/hugo-menu.lua"]

[tasks."test:contract:ai"]
description = "🔏 Test AI model selection contract specifications"
run = "mise run test:_run_plenary_file tests/contract/ai_model_selection_spec.lua"
sources = ["tests/contract/ai_model_selection_spec.lua", "lua/percybrain/ai-model-selector.lua"]

[tasks."test:contract:write-quit"]
description = "🔏 Test Write-Quit AI Pipeline contract specifications"
run = "mise run test:_run_plenary_file tests/contract/write_quit_pipeline_spec.lua"
sources = ["tests/contract/write_quit_pipeline_spec.lua", "lua/percybrain/write-quit-pipeline.lua"]

# ----------------------------------------------------------------------------
# CAPABILITY TESTS - Tests that features WORK
# ----------------------------------------------------------------------------
[tasks."test:capability"]
description = "🎯 Capability Tests - Verify features work as expected"
alias = "tcap"
run = "mise run test:_run_plenary_dir capability"
sources = ["tests/capability/**/*.lua", "lua/**/*.lua"]
outputs = [".cache/test/capability-results.json"]

[tasks."test:capability:zettelkasten"]
description = "🎯 Test Zettelkasten capabilities"
run = "mise run test:_run_plenary_dir capability/zettelkasten"
sources = ["tests/capability/zettelkasten/**/*.lua", "lua/config/zettelkasten.lua", "lua/plugins/zettelkasten/**/*.lua"]

[tasks."test:capability:ai"]
description = "🎯 Test AI/Ollama capabilities"
run = "mise run test:_run_plenary_dir capability/ai"
sources = ["tests/capability/ai/**/*.lua", "lua/plugins/ai-sembr/**/*.lua", "lua/percybrain/ai-model-selector.lua"]

[tasks."test:capability:write-quit"]
description = "🎯 Test Write-Quit AI Pipeline capabilities"
run = "mise run test:_run_plenary_dir capability/write-quit"
sources = ["tests/capability/write-quit/**/*.lua", "lua/percybrain/write-quit-pipeline.lua"]

[tasks."test:capability:hugo"]
description = "🎯 Test Hugo frontmatter and publishing capabilities"
run = "mise run test:_run_plenary_dir capability/hugo"
sources = ["tests/capability/hugo/**/*.lua", "lua/percybrain/hugo-menu.lua"]

# ----------------------------------------------------------------------------
# REGRESSION TESTS - Protect critical behaviors
# ----------------------------------------------------------------------------
[tasks."test:regression"]
description = "🛡️ Regression Tests - Ensure critical ADHD optimizations remain intact"
alias = "tr"
run = "mise run test:_run_plenary_dir regression"
sources = ["tests/regression/**/*.lua", "lua/config/options.lua"]
outputs = [".cache/test/regression-results.json"]

[tasks."test:regression:adhd"]
description = "🛡️ Test ADHD-specific optimizations are preserved"
run = "mise run test:_run_plenary_file tests/regression/adhd_protections_spec.lua"
sources = ["tests/regression/adhd_protections_spec.lua", "lua/config/options.lua"]

# ----------------------------------------------------------------------------
# STARTUP TESTS - Smoke tests for clean startup
# ----------------------------------------------------------------------------
[tasks."test:startup"]
description = "🚀 Startup Smoke Tests - Verify clean startup without warnings"
alias = "ts"
run = "mise run test:_run_plenary_dir performance"
sources = ["tests/performance/**/*.lua", "lua/plugins/**/*.lua"]
outputs = [".cache/test/startup-results.json"]

# ----------------------------------------------------------------------------
# INTEGRATION TESTS - Component interactions
# ----------------------------------------------------------------------------
[tasks."test:integration"]
description = "🔗 Integration Tests - Test component interactions"
alias = "ti"
run = "mise run test:_run_plenary_dir integration"
sources = ["tests/integration/**/*.lua", "lua/**/*.lua"]
outputs = [".cache/test/integration-results.json"]

# ----------------------------------------------------------------------------
# UNIT TESTS - Individual component testing
# ----------------------------------------------------------------------------
[tasks."test:unit"]
description = "📦 Unit Tests - Individual component testing"
alias = "tu"
run = "mise run test:_run_plenary_dir unit"
sources = ["tests/unit/**/*.lua", "lua/**/*.lua"]
outputs = [".cache/test/unit-results.json"]

# ----------------------------------------------------------------------------
# COMPOSITE TEST WORKFLOWS
# ----------------------------------------------------------------------------
[tasks.test]
description = "🧪 Run all tests in order: startup → contract → capability → regression → integration"
alias = "t"
depends = ["test:startup", "test:contract", "test:capability", "test:regression", "test:integration"]

[tasks."test:quick"]
description = "⚡ Quick test run - startup + contract + regression (fast feedback)"
alias = "tq"
depends = ["test:startup", "test:contract", "test:regression"]

[tasks."test:comprehensive"]
description = "🔬 Comprehensive test suite with coverage analysis"
alias = "tcomp"
run = """
#!/bin/bash

echo "🧪 PercyBrain Comprehensive Test Suite"
echo "======================================="
echo ""

# Create results directory
mkdir -p .cache/test
> .cache/test/status.json  # Clear status file

# Track failures
FAILED_COUNT=0

run_test() {
  TEST_NAME=$1
  TEST_COMMAND=$2

  echo "$TEST_NAME..."
  if time mise run "$TEST_COMMAND"; then
    echo "{\"test\": \"$TEST_NAME\", \"status\": \"PASSED\"}" >> .cache/test/status.json
  else
    echo "{\"test\": \"$TEST_NAME\", \"status\": \"FAILED\"}" >> .cache/test/status.json
    FAILED_COUNT=$((FAILED_COUNT + 1))
  fi
  echo ""
}

# Run each test type with timing
run_test "🚀 Startup Smoke Tests" "test:startup"
run_test "🔏 Contract Tests" "test:contract"
run_test "🎯 Capability Tests" "test:capability"
run_test "🛡️ Regression Tests" "test:regression"
run_test "🔗 Integration Tests" "test:integration"

# Generate report
mise run test:report

# Summary
echo ""
echo "======================================="
if [ $FAILED_COUNT -eq 0 ]; then
  echo "✅ All tests passed!"
  exit 0
else
  echo "❌ $FAILED_COUNT test suite(s) failed"
  echo "See status: cat .cache/test/status.json"
  exit 1
fi
"""

[tasks."test:watch"]
description = "👁️ Watch all tests with intelligent re-running"
alias = "tw"
run = """
#!/bin/bash
mise run test:_watch test "tests/**/*.lua" "lua/**/*.lua"
"""

[tasks."test:watch:focused"]
description = "👁️ Watch focused test type (use TEST_TYPE env var)"
run = """
#!/bin/bash
TEST_TYPE="${TEST_TYPE:-capability}"
mise run test:_watch test:$TEST_TYPE "tests/$TEST_TYPE/**/*.lua" "lua/**/*.lua"
"""

# ----------------------------------------------------------------------------
# TEST UTILITIES
# ----------------------------------------------------------------------------
[tasks."test:report"]
description = "📊 Generate test report from cached results"
run = """
#!/bin/bash
echo "📊 Test Results Report"
echo "====================="
echo ""

report_test_type() {
  TYPE=$1
  FILE=$2

  if [ -f "$FILE" ]; then
    PASSED=$(grep -c "PASS" "$FILE" 2>/dev/null || echo "0")
    FAILED=$(grep -c "FAIL" "$FILE" 2>/dev/null || echo "0")
    echo "$TYPE: $PASSED passed, $FAILED failed"
  else
    echo "$TYPE: No results cached (run 'mise test:${TYPE,,}')"
  fi
}

report_test_type "Contract Tests   " ".cache/test/contract-results.json"
report_test_type "Capability Tests " ".cache/test/capability-results.json"
report_test_type "Regression Tests " ".cache/test/regression-results.json"
report_test_type "Integration Tests" ".cache/test/integration-results.json"
report_test_type "Startup Tests    " ".cache/test/startup-results.json"

echo ""
echo "Run 'mise test:clean' to clear cache"
"""

[tasks."test:clean"]
description = "🧹 Clean test cache and artifacts"
run = """
rm -rf .cache/test
rm -f tests/*.log
echo "✅ Test artifacts cleaned"
"""

[tasks."test:debug"]
description = "🐛 Run tests with verbose output for debugging"
run = """
TEST_VERBOSITY=verbose mise run test
"""

[tasks."test:profile"]
description = "⏱️ Profile test performance to identify slow tests"
run = """
#!/bin/bash
echo "⏱️ Test Performance Profile"
echo "==========================="

for type in contract capability regression integration; do
  echo ""
  echo "Testing $type..."
  time nvim --headless -u tests/minimal_init.lua \
    -c "PlenaryBustedDirectory tests/$type/ {minimal_init = 'tests/minimal_init.lua'}" \
    -c "qa!" 2>&1 | grep -E "(Success:|Failed:|Time:)"
done
"""

# Internal watch helper (not user-facing)
[tasks."test:_watch"]
description = "Internal watch helper"
run = """
#!/bin/bash
TASK=$1
shift
FILES="$@"

echo "👁️ Watching for changes..."
echo "Task: $TASK"
echo "Files: $FILES"
echo ""

# Use md5sum for change detection
get_checksum() {
  find $FILES -type f 2>/dev/null | xargs md5sum 2>/dev/null | md5sum
}

LAST_CHECKSUM=$(get_checksum)

while true; do
  clear
  echo "Running: mise run $TASK"
  echo "========================"
  mise run $TASK || true

  echo ""
  echo "Waiting for changes... (Ctrl+C to exit)"

  while true; do
    sleep 1
    CURRENT_CHECKSUM=$(get_checksum)
    if [ "$CURRENT_CHECKSUM" != "$LAST_CHECKSUM" ]; then
      LAST_CHECKSUM=$CURRENT_CHECKSUM
      break
    fi
  done
done
"""

# ----------------------------------------------------------------------------
# MIGRATION HELPER
# ----------------------------------------------------------------------------
[tasks."test:migrate"]
description = "🔄 Migrate existing tests to new structure"
run = """
#!/bin/bash
echo "🔄 Migrating tests to Kent Beck architecture..."

# Create new directories
mkdir -p tests/{contract,capability,regression,integration}
mkdir -p tests/capability/{zettelkasten,ai,ui,prose}
mkdir -p specs

echo "✅ Created new test directories"
echo ""
echo "Next steps:"
echo "1. Review specs/percybrain_contract.lua"
echo "2. Move tests to appropriate directories:"
echo "   - Contract tests → tests/contract/"
echo "   - Feature tests → tests/capability/"
echo "   - ADHD protections → tests/regression/"
echo "   - Multi-component → tests/integration/"
echo "3. Run 'mise test:quick' for fast feedback"
echo "4. Run 'mise test' for full suite"
"""

# ----------------------------------------------------------------------------
# CODE QUALITY TASKS (Existing)
# ----------------------------------------------------------------------------
[tasks.lint]
description = "Run luacheck static analysis on lua/ directory"
alias = "l"
run = "luacheck lua/ --no-color --codes"
sources = ["lua/**/*.lua", ".luacheckrc"]

[tasks.format]
description = "Auto-format Lua code with stylua"
alias = "f"
run = "stylua ."
sources = ["lua/**/*.lua", "tests/**/*.lua", "hooks/**/*.lua"]

[tasks."format:check"]
description = "Check stylua formatting without making changes"
run = "stylua --check ."
sources = ["lua/**/*.lua", "tests/**/*.lua", "hooks/**/*.lua"]

# ----------------------------------------------------------------------------
# PRE-COMMIT TASKS (Existing)
# ----------------------------------------------------------------------------
[tasks."hooks:install"]
description = "Install pre-commit git hooks"
run = "pre-commit install"
outputs = [".git/hooks/pre-commit"]

[tasks."hooks:run"]
description = "Run all pre-commit hooks manually on all files"
run = "pre-commit run --all-files"

# ----------------------------------------------------------------------------
# COMPOSITE QUALITY TASKS
# ----------------------------------------------------------------------------
[tasks.check]
description = "Full quality check: lint + format + test:quick + hooks"
depends = ["lint", "format:check", "test:quick", "hooks:run"]

[tasks.quick]
description = "Quick validation: lint + format check (fast feedback)"
alias = "q"
depends = ["lint", "format:check"]

[tasks.fix]
description = "Auto-fix all issues: format + hooks"
depends = ["format", "hooks:run"]

[tasks.ci]
description = "CI pipeline: comprehensive tests + quality checks"
depends = ["lint", "format:check", "test:comprehensive", "hooks:run"]

# ----------------------------------------------------------------------------
# DEVELOPMENT SETUP
# ----------------------------------------------------------------------------
[tasks.setup]
description = "First-time development setup with new test framework"
run = """
#!/bin/bash
set -e

echo "📦 Installing tools from mise.toml..."
mise install

echo ""
echo "🪝 Installing pre-commit hooks..."
pre-commit install

echo ""
echo "🏗️ Setting up test framework..."
mise run test:migrate

echo ""
echo "🧪 Running initial test suite..."
mise run test:quick || echo "⚠️  Some tests failed - expected during migration"

echo ""
echo "✅ Setup complete!"
echo ""
echo "Test commands:"
echo "  mise test         - Run all tests"
echo "  mise test:quick   - Fast feedback (contract + regression)"
echo "  mise test:watch   - Watch mode"
echo "  mise tc          - Contract tests only"
echo "  mise tcap        - Capability tests only"
echo "  mise tr          - Regression tests only"
"""

# ============================================================================
# METADATA
# ============================================================================
[_]
project = "PercyBrain"
description = "Neovim Zettelkasten + AI Writing Environment with Kent Beck Testing"
test_philosophy = "Test capabilities, not configuration"
